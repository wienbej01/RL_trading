{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Ticker RL Trading System Examples\n",
    "\n",
    "This notebook provides examples and tutorials for using the Multi-Ticker RL Trading System. It covers basic usage, advanced features, and custom implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.config_loader import load_config\n",
    "from src.data.multiticker_data_loader import MultiTickerDataLoader\n",
    "from src.features.multiticker_pipeline import MultiTickerFeaturePipeline\n",
    "from src.sim.multiticker_env import MultiTickerIntradayRLEnv\n",
    "from src.rl.multiticker_trainer import MultiTickerRLTrainer\n",
    "from src.rl.multiticker_policy import MultiTickerPPOLSTMPolicy\n",
    "from src.evaluation.multiticker_evaluator import MultiTickerEvaluator\n",
    "from src.monitoring.multiticker_monitor import MultiTickerMonitor\n",
    "\n",
    "# Set logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Multi-Ticker Training\n",
    "\n",
    "In this example, we'll train a basic multi-ticker RL model using the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "\n",
    "# Print configuration overview\n",
    "print(\"Configuration Overview:\")\n",
    "print(f\"- Tickers: {config['data']['tickers']}\")\n",
    "print(f\"- Start Date: {config['data']['start_date']}\")\n",
    "print(f\"- End Date: {config['data']['end_date']}\")\n",
    "print(f\"- Reward Type: {config['environment']['reward_type']}\")\n",
    "print(f\"- Training Timesteps: {config['training']['total_timesteps']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = MultiTickerDataLoader(config['data'])\n",
    "\n",
    "# Load data\n",
    "print(\"Loading market data...\")\n",
    "data = data_loader.load_data()\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Date range: {data.index.min()} to {data.index.max()}\")\n",
    "print(f\"Number of tickers: {len(data.columns.get_level_values('ticker').unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature pipeline\n",
    "feature_pipeline = MultiTickerFeaturePipeline(config['features'])\n",
    "\n",
    "# Fit and transform features\n",
    "print(\"Extracting features...\")\n",
    "features = feature_pipeline.fit_transform(data)\n",
    "\n",
    "print(f\"Features extracted successfully!\")\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Number of features: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = MultiTickerRLTrainer(config)\n",
    "\n",
    "# Train model (reduced timesteps for example)\n",
    "print(\"Training model...\")\n",
    "config['training']['total_timesteps'] = 10000  # Reduced for example\n",
    "model = trainer.train()\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = \"models/basic_multiticker_model\"\n",
    "trainer.save_model(model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Model Evaluation\n",
    "\n",
    "Now let's evaluate the trained model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = MultiTickerPPOLSTMPolicy.load(model_path)\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = MultiTickerEvaluator(config['evaluation'])\n",
    "\n",
    "# Split data for training and testing\n",
    "split_date = data.index.max() - timedelta(days=30)\n",
    "train_data = data[data.index <= split_date]\n",
    "test_data = data[data.index > split_date]\n",
    "\n",
    "print(f\"Training data: {train_data.index.min()} to {train_data.index.max()}\")\n",
    "print(f\"Test data: {test_data.index.min()} to {test_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model...\")\n",
    "results = evaluator.evaluate_model(model, test_data)\n",
    "\n",
    "# Print key metrics\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"Sharpe Ratio: {results['sharpe_ratio']:.2f}\")\n",
    "print(f\"Total Return: {results['total_return']:.2%}\")\n",
    "print(f\"Annualized Return: {results['annualized_return']:.2%}\")\n",
    "print(f\"Max Drawdown: {results['max_drawdown']:.2%}\")\n",
    "print(f\"Win Rate: {results['win_rate']:.2%}\")\n",
    "print(f\"Profit Factor: {results['profit_factor']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "equity_curve = pd.DataFrame(results['equity_curve'])\n",
    "equity_curve.set_index('timestamp', inplace=True)\n",
    "plt.plot(equity_curve.index, equity_curve['equity'], label='Portfolio Value')\n",
    "plt.title('Portfolio Equity Curve')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot drawdown\n",
    "plt.figure(figsize=(12, 6))\n",
    "equity_series = equity_curve['equity']\n",
    "cummax = equity_series.cummax()\n",
    "drawdown = (equity_series - cummax) / cummax\n",
    "plt.fill_between(drawdown.index, drawdown, 0, alpha=0.3, color='red')\n",
    "plt.plot(drawdown.index, drawdown, color='red')\n",
    "plt.title('Portfolio Drawdown')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Drawdown (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Walk-Forward Optimization\n",
    "\n",
    "In this example, we'll implement walk-forward optimization with Leave-One-Ticker-Out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure walk-forward optimization\n",
    "wfo_config = config.copy()\n",
    "wfo_config['walkforward'] = {\n",
    "    'enabled': True,\n",
    "    'n_folds': 3,  # Reduced for example\n",
    "    'embargo_days': 5,\n",
    "    'test_size': 0.2,\n",
    "    'regime_aware': True\n",
    "}\n",
    "\n",
    "# Initialize trainer with WFO\n",
    "wfo_trainer = MultiTickerRLTrainer(wfo_config)\n",
    "\n",
    "# Run walk-forward optimization\n",
    "print(\"Running walk-forward optimization...\")\n",
    "wfo_results = wfo_trainer.walk_forward_training()\n",
    "\n",
    "print(\"Walk-forward optimization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print WFO results\n",
    "print(\"\\nWalk-Forward Optimization Results:\")\n",
    "print(f\"Average Sharpe Ratio: {wfo_results['avg_sharpe_ratio']:.2f}\")\n",
    "print(f\"Average Total Return: {wfo_results['avg_total_return']:.2%}\")\n",
    "print(f\"Average Max Drawdown: {wfo_results['avg_max_drawdown']:.2%}\")\n",
    "print(f\"Fold Results: {wfo_results['fold_results']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fold performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "fold_results = wfo_results['fold_results']\n",
    "fold_names = list(fold_results.keys())\n",
    "sharpe_ratios = [fold_results[fold]['sharpe_ratio'] for fold in fold_names]\n",
    "total_returns = [fold_results[fold]['total_return'] for fold in fold_names]\n",
    "\n",
    "x = np.arange(len(fold_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot Sharpe ratios\n",
    "ax1.bar(x - width/2, sharpe_ratios, width, label='Sharpe Ratio', color='skyblue')\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('Sharpe Ratio', color='skyblue')\n",
    "ax1.tick_params(axis='y', labelcolor='skyblue')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(fold_names)\n",
    "\n",
    "# Plot total returns on secondary axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(x + width/2, total_returns, width, label='Total Return', color='lightgreen')\n",
    "ax2.set_ylabel('Total Return', color='lightgreen')\n",
    "ax2.tick_params(axis='y', labelcolor='lightgreen')\n",
    "\n",
    "plt.title('Walk-Forward Optimization Fold Performance')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Hyperparameter Optimization\n",
    "\n",
    "In this example, we'll use Optuna to optimize hyperparameters for the multi-ticker RL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure hyperparameter optimization\n",
    "hpo_config = config.copy()\n",
    "hpo_config['hpo'] = {\n",
    "    'enabled': True,\n",
    "    'n_trials': 10,  # Reduced for example\n",
    "    'direction': 'maximize',\n",
    "    'metric': 'sharpe_ratio',\n",
    "    'pruner': 'median',\n",
    "    'sampler': 'tpe',\n",
    "    'search_space': {\n",
    "        'learning_rate': {'type': 'float', 'low': 1e-5, 'high': 1e-3, 'log': True},\n",
    "        'batch_size': {'type': 'categorical', 'choices': [32, 64, 128]},\n",
    "        'n_steps': {'type': 'categorical', 'choices': [1024, 2048, 4096]},\n",
    "        'gamma': {'type': 'float', 'low': 0.9, 'high': 0.999},\n",
    "        'gae_lambda': {'type': 'float', 'low': 0.8, 'high': 0.99},\n",
    "        'clip_range': {'type': 'float', 'low': 0.1, 'high': 0.4},\n",
    "        'ent_coef': {'type': 'float', 'low': 1e-4, 'high': 0.1, 'log': True},\n",
    "        'vf_coef': {'type': 'float', 'low': 0.1, 'high': 1.0}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize trainer with HPO\n",
    "hpo_trainer = MultiTickerRLTrainer(hpo_config)\n",
    "\n",
    "# Run hyperparameter optimization\n",
    "print(\"Running hyperparameter optimization...\")\n",
    "hpo_results = hpo_trainer.optimize_hyperparameters()\n",
    "\n",
    "print(\"Hyperparameter optimization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print HPO results\n",
    "print(\"\\nHyperparameter Optimization Results:\")\n",
    "print(\"Best parameters:\")\n",
    "for param, value in hpo_results['best_params'].items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest Sharpe Ratio: {hpo_results['best_value']:.2f}\")\n",
    "print(f\"Number of trials: {len(hpo_results['history'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization history\n",
    "plt.figure(figsize=(12, 6))\n",
    "history = hpo_results['history']\n",
    "trials = list(range(1, len(history) + 1))\n",
    "values = [trial['value'] for trial in history]\n",
    "\n",
    "plt.plot(trials, values, 'o-')\n",
    "plt.axhline(y=hpo_results['best_value'], color='r', linestyle='--', label='Best Value')\n",
    "plt.title('Hyperparameter Optimization History')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Custom Reward Function\n",
    "\n",
    "In this example, we'll implement a custom reward function that emphasizes diversification and risk management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom reward calculator\n",
    "from src.sim.multiticker_env import MultiTickerRewardCalculator\n",
    "\n",
    "class CustomRewardCalculator(MultiTickerRewardCalculator):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def calculate_reward(self, portfolio_state, action, next_portfolio_state):\n",
    "        # Calculate base reward\n",
    "        base_reward = super().calculate_reward(portfolio_state, action, next_portfolio_state)\n",
    "        \n",
    "        # Add custom reward for diversification\n",
    "        diversification_reward = self._calculate_diversification_reward(portfolio_state)\n",
    "        \n",
    "        # Add custom penalty for concentration\n",
    "        concentration_penalty = self._calculate_concentration_penalty(portfolio_state)\n",
    "        \n",
    "        # Add custom reward for risk-adjusted returns\n",
    "        risk_adjusted_reward = self._calculate_risk_adjusted_reward(portfolio_state, next_portfolio_state)\n",
    "        \n",
    "        # Combine rewards\n",
    "        total_reward = base_reward + diversification_reward - concentration_penalty + risk_adjusted_reward\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def _calculate_diversification_reward(self, portfolio_state):\n",
    "        positions = portfolio_state['positions']\n",
    "        if len(positions) <= 1:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate Herfindahl-Hirschman Index (HHI)\n",
    "        total_value = sum(abs(pos) for pos in positions.values())\n",
    "        if total_value == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        hhi = sum((abs(pos) / total_value) ** 2 for pos in positions.values())\n",
    "        \n",
    "        # Reward for lower HHI (more diversified)\n",
    "        diversification_reward = (1 - hhi) * 0.1\n",
    "        \n",
    "        return diversification_reward\n",
    "    \n",
    "    def _calculate_concentration_penalty(self, portfolio_state):\n",
    "        positions = portfolio_state['positions']\n",
    "        if len(positions) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate concentration\n",
    "        total_value = sum(abs(pos) for pos in positions.values())\n",
    "        if total_value == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        max_concentration = max(abs(pos) / total_value for pos in positions.values())\n",
    "        \n",
    "        # Penalty for high concentration\n",
    "        if max_concentration > 0.4:\n",
    "            concentration_penalty = (max_concentration - 0.4) * 0.2\n",
    "        else:\n",
    "            concentration_penalty = 0.0\n",
    "        \n",
    "        return concentration_penalty\n",
    "    \n",
    "    def _calculate_risk_adjusted_reward(self, portfolio_state, next_portfolio_state):\n",
    "        # Calculate portfolio returns\n",
    "        current_value = portfolio_state['portfolio_value']\n",
    "        next_value = next_portfolio_state['portfolio_value']\n",
    "        \n",
    "        if current_value == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        portfolio_return = (next_value - current_value) / current_value\n",
    "        \n",
    "        # Calculate portfolio volatility (simplified)\n",
    "        positions = portfolio_state['positions']\n",
    "        if len(positions) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Use position sizes as proxy for risk\n",
    "        position_sizes = [abs(pos) for pos in positions.values()]\n",
    "        portfolio_volatility = np.std(position_sizes) / np.mean(position_sizes) if np.mean(position_sizes) > 0 else 0.0\n",
    "        \n",
    "        # Calculate risk-adjusted return (simplified Sharpe ratio)\n",
    "        if portfolio_volatility > 0:\n",
    "            risk_adjusted_return = portfolio_return / portfolio_volatility\n",
    "        else:\n",
    "            risk_adjusted_return = 0.0\n",
    "        \n",
    "        # Scale reward\n",
    "        risk_adjusted_reward = risk_adjusted_return * 0.05\n",
    "        \n",
    "        return risk_adjusted_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure custom reward training\n",
    "custom_reward_config = config.copy()\n",
    "custom_reward_config['environment']['reward_calculator'] = CustomRewardCalculator\n",
    "custom_reward_config['training']['total_timesteps'] = 10000  # Reduced for example\n",
    "\n",
    "# Initialize trainer with custom reward\n",
    "custom_trainer = MultiTickerRLTrainer(custom_reward_config)\n",
    "\n",
    "# Train model with custom reward\n",
    "print(\"Training model with custom reward function...\")\n",
    "custom_model = custom_trainer.train()\n",
    "\n",
    "print(\"Model with custom reward function trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate custom reward model\n",
    "print(\"Evaluating custom reward model...\")\n",
    "custom_results = evaluator.evaluate_model(custom_model, test_data)\n",
    "\n",
    "# Print key metrics\n",
    "print(\"\\nCustom Reward Model Evaluation Results:\")\n",
    "print(f\"Sharpe Ratio: {custom_results['sharpe_ratio']:.2f}\")\n",
    "print(f\"Total Return: {custom_results['total_return']:.2%}\")\n",
    "print(f\"Annualized Return: {custom_results['annualized_return']:.2%}\")\n",
    "print(f\"Max Drawdown: {custom_results['max_drawdown']:.2%}\")\n",
    "print(f\"Win Rate: {custom_results['win_rate']:.2%}\")\n",
    "print(f\"Profit Factor: {custom_results['profit_factor']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with baseline model\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot equity curves\n",
    "baseline_equity = pd.DataFrame(results['equity_curve'])\n",
    "baseline_equity.set_index('timestamp', inplace=True)\n",
    "plt.plot(baseline_equity.index, baseline_equity['equity'], label='Baseline Model')\n",
    "\n",
    "custom_equity = pd.DataFrame(custom_results['equity_curve'])\n",
    "custom_equity.set_index('timestamp', inplace=True)\n",
    "plt.plot(custom_equity.index, custom_equity['equity'], label='Custom Reward Model')\n",
    "\n",
    "plt.title('Model Comparison: Equity Curves')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Dynamic Universe Selection\n",
    "\n",
    "In this example, we'll implement a dynamic universe selection strategy that adapts to changing market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom universe selector\n",
    "from src.data.multiticker_data_loader import MultiTickerDataLoader\n",
    "\n",
    "class DynamicUniverseSelector:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.max_tickers = config.get('max_tickers', 10)\n",
    "        self.min_tickers = config.get('min_tickers', 3)\n",
    "        self.rebalance_freq = config.get('rebalance_freq', '1M')\n",
    "        self.selection_metrics = config.get('selection_metrics', ['liquidity', 'volatility', 'trend_strength'])\n",
    "        \n",
    "    def select_universe(self, data, current_universe=None, date=None):\n",
    "        \"\"\"\n",
    "        Select universe of tickers based on custom criteria.\n",
    "        \"\"\"\n",
    "        # Get all available tickers\n",
    "        all_tickers = data.columns.get_level_values('ticker').unique()\n",
    "        \n",
    "        # Calculate selection metrics for each ticker\n",
    "        ticker_metrics = {}\n",
    "        \n",
    "        for ticker in all_tickers:\n",
    "            if (ticker, 'close') in data.columns:\n",
    "                prices = data[(ticker, 'close')]\n",
    "                volume = data[(ticker, 'volume')] if (ticker, 'volume') in data.columns else None\n",
    "                \n",
    "                # Calculate selection metrics\n",
    "                metrics = self._calculate_selection_metrics(prices, volume)\n",
    "                ticker_metrics[ticker] = metrics\n",
    "        \n",
    "        # Score and rank tickers\n",
    "        ticker_scores = {}\n",
    "        for ticker, metrics in ticker_metrics.items():\n",
    "            score = self._calculate_ticker_score(metrics)\n",
    "            ticker_scores[ticker] = score\n",
    "        \n",
    "        # Sort tickers by score\n",
    "        sorted_tickers = sorted(ticker_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Select top tickers\n",
    "        selected_tickers = [ticker for ticker, _ in sorted_tickers[:self.max_tickers]]\n",
    "        \n",
    "        # Ensure minimum number of tickers\n",
    "        if len(selected_tickers) < self.min_tickers:\n",
    "            selected_tickers = [ticker for ticker, _ in sorted_tickers[:self.min_tickers]]\n",
    "        \n",
    "        return selected_tickers\n",
    "    \n",
    "    def _calculate_selection_metrics(self, prices, volume=None):\n",
    "        metrics = {}\n",
    "        \n",
    "        # Liquidity metric\n",
    "        if volume is not None:\n",
    "            metrics['liquidity'] = volume.mean()\n",
    "        else:\n",
    "            metrics['liquidity'] = 1.0\n",
    "        \n",
    "        # Volatility metric\n",
    "        returns = prices.pct_change().dropna()\n",
    "        metrics['volatility'] = returns.std()\n",
    "        \n",
    "        # Trend strength metric\n",
    "        metrics['trend_strength'] = self._calculate_trend_strength(prices)\n",
    "        \n",
    "        # Price momentum\n",
    "        metrics['momentum'] = (prices.iloc[-1] / prices.iloc[-21]) - 1 if len(prices) >= 21 else 0.0\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _calculate_trend_strength(self, prices):\n",
    "        # Calculate trend strength using linear regression\n",
    "        x = np.arange(len(prices))\n",
    "        y = prices.values\n",
    "        \n",
    "        # Remove NaN values\n",
    "        mask = ~np.isnan(y)\n",
    "        x = x[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        if len(x) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate linear regression\n",
    "        slope, _ = np.polyfit(x, y, 1)\n",
    "        \n",
    "        # Normalize slope by price level\n",
    "        trend_strength = slope / np.mean(y) if np.mean(y) != 0 else 0.0\n",
    "        \n",
    "        return trend_strength\n",
    "    \n",
    "    def _calculate_ticker_score(self, metrics):\n",
    "        # Calculate composite score from metrics\n",
    "        liquidity_score = min(metrics['liquidity'] / 1e6, 1.0)\n",
    "        volatility_score = min(metrics['volatility'] / 0.02, 1.0)\n",
    "        trend_score = min(abs(metrics['trend_strength']) * 100, 1.0)\n",
    "        momentum_score = min(abs(metrics['momentum']) * 10, 1.0)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        score = (\n",
    "            0.2 * liquidity_score +\n",
    "            0.3 * volatility_score +\n",
    "            0.25 * trend_score +\n",
    "            0.25 * momentum_score\n",
    "        )\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dynamic universe selection\n",
    "dynamic_universe_config = config.copy()\n",
    "dynamic_universe_config['multiticker'] = {\n",
    "    'universe': {\n",
    "        'selection_method': 'dynamic',\n",
    "        'max_tickers': 5,\n",
    "        'min_tickers': 3,\n",
    "        'rebalance_freq': '1M',\n",
    "        'selection_metrics': ['liquidity', 'volatility', 'trend_strength'],\n",
    "        'selector_class': DynamicUniverseSelector\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize data loader with dynamic universe\n",
    "dynamic_data_loader = MultiTickerDataLoader(dynamic_universe_config['data'])\n",
    "dynamic_data_loader.universe_selector = DynamicUniverseSelector(dynamic_universe_config['multiticker']['universe'])\n",
    "\n",
    "# Load data with dynamic universe\n",
    "print(\"Loading data with dynamic universe selection...\")\n",
    "dynamic_data = dynamic_data_loader.load_data()\n",
    "\n",
    "print(f\"Dynamic universe data loaded successfully!\")\n",
    "print(f\"Data shape: {dynamic_data.shape}\")\n",
    "print(f\"Number of tickers: {len(dynamic_data.columns.get_level_values('ticker').unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate dynamic universe selection over time\n",
    "print(\"Simulating dynamic universe selection over time...\")\n",
    "\n",
    "# Get monthly dates\n",
    "monthly_dates = pd.date_range(start=data.index.min(), end=data.index.max(), freq='MS')\n",
    "\n",
    "universe_history = []\n",
    "\n",
    "for date in monthly_dates:\n",
    "    # Get data up to current date\n",
    "    data_up_to_date = data[data.index <= date]\n",
    "    \n",
    "    if len(data_up_to_date) > 21:  # Ensure we have enough data\n",
    "        # Select universe\n",
    "        universe = dynamic_data_loader.universe_selector.select_universe(data_up_to_date, date=date)\n",
    "        \n",
    "        universe_history.append({\n",
    "            'date': date,\n",
    "            'universe': universe\n",
    "        })\n",
    "\n",
    "# Print universe selection history\n",
    "print(\"\\nDynamic Universe Selection History:\")\n",
    "for entry in universe_history[-5:]:  # Show last 5 months\n",
    "    print(f\"{entry['date'].strftime('%Y-%m-%d')}: {entry['universe']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Performance Benchmarking\n",
    "\n",
    "In this example, we'll benchmark the RL model against various baseline strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import benchmarking framework\n",
    "from tests.performance_benchmarking import PerformanceBenchmarkingFramework, BenchmarkStrategy\n",
    "\n",
    "# Initialize benchmarking framework\n",
    "benchmark_config = config.copy()\n",
    "benchmark_config['benchmarking'] = {\n",
    "    'output_dir': '/tmp/benchmarking_results',\n",
    "    'significance_level': 0.05\n",
    "}\n",
    "\n",
    "benchmark_framework = PerformanceBenchmarkingFramework(benchmark_config)\n",
    "\n",
    "# Add default benchmark strategies\n",
    "benchmark_strategies = benchmark_framework.add_default_benchmark_strategies()\n",
    "\n",
    "print(f\"Added {len(benchmark_strategies)} benchmark strategies:\")\n",
    "for strategy in benchmark_strategies:\n",
    "    print(f\"  - {strategy.name}: {strategy.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarking analysis\n",
    "print(\"Running benchmarking analysis...\")\n",
    "benchmark_results = benchmark_framework.run_benchmarks(test_data, model, parallel=False)\n",
    "\n",
    "print(\"Benchmarking analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print benchmarking results\n",
    "print(\"\\nBenchmarking Results:\")\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "for metric, strategies in benchmark_results['comparison']['metrics_comparison'].items():\n",
    "    print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "    for strategy, value in strategies.items():\n",
    "        print(f\"  {strategy}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rankings\n",
    "print(\"\\nRankings:\")\n",
    "for metric, ranking in benchmark_results['comparison']['ranking'].items():\n",
    "    print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "    for i, (strategy, value) in enumerate(ranking[:3]):  # Top 3\n",
    "        print(f\"  {i+1}. {strategy}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistical tests\n",
    "print(\"\\nStatistical Tests:\")\n",
    "for strategy_name, tests in benchmark_results['statistical_tests']['t_tests'].items():\n",
    "    significant = \"(significant)\" if tests['significant'] else \"(not significant)\"\n",
    "    print(f\"\\n{strategy_name}:\")\n",
    "    print(f\"  T-test p-value: {tests['p_value']:.4f} {significant}\")\n",
    "    \n",
    "    if strategy_name in benchmark_results['statistical_tests']['bootstrap']:\n",
    "        bootstrap_test = benchmark_results['statistical_tests']['bootstrap'][strategy_name]\n",
    "        significant = \"(significant)\" if bootstrap_test['significant'] else \"(not significant)\"\n",
    "        print(f\"  Bootstrap p-value: {bootstrap_test['p_value']:.4f} {significant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot benchmarking results\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get key metrics\n",
    "key_metrics = ['sharpe_ratio', 'total_return', 'max_drawdown']\n",
    "\n",
    "for i, metric in enumerate(key_metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    \n",
    "    if metric in benchmark_results['comparison']['metrics_comparison']:\n",
    "        strategies = list(benchmark_results['comparison']['metrics_comparison'][metric].keys())\n",
    "        values = list(benchmark_results['comparison']['metrics_comparison'][metric].values())\n",
    "        \n",
    "        bars = plt.bar(strategies, values)\n",
    "        \n",
    "        # Highlight RL model\n",
    "        if 'RL Model' in strategies:\n",
    "            rl_index = strategies.index('RL Model')\n",
    "            bars[rl_index].set_color('red')\n",
    "        \n",
    "        plt.title(metric.replace('_', ' ').title())\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Real-time Monitoring\n",
    "\n",
    "In this example, we'll set up real-time monitoring for the trading system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure monitoring\n",
    "monitoring_config = config.copy()\n",
    "monitoring_config['monitoring'] = {\n",
    "    'enabled': True,\n",
    "    'output_dir': '/tmp/monitoring_results',\n",
    "    'alert_thresholds': {\n",
    "        'drawdown': 0.15,\n",
    "        'sharpe_ratio': 0.5,\n",
    "        'win_rate': 0.45,\n",
    "        'var_95': 0.05\n",
    "    },\n",
    "    'dashboard': {\n",
    "        'enabled': True,\n",
    "        'port': 8080,\n",
    "        'update_interval': 60\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = MultiTickerMonitor(monitoring_config['monitoring'])\n",
    "\n",
    "print(\"Monitoring initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real-time monitoring\n",
    "print(\"Simulating real-time monitoring...\")\n",
    "\n",
    "# Get sample data for monitoring\n",
    "sample_data = test_data.head(100)  # Use first 100 data points for simulation\n",
    "\n",
    "# Initialize monitoring state\n",
    "monitor.initialize_monitoring()\n",
    "\n",
    "# Simulate trading and monitoring\n",
    "for i, (timestamp, row) in enumerate(sample_data.iterrows()):\n",
    "    # Simulate trading decision (simplified)\n",
    "    if i % 5 == 0:  # Make a trade every 5 steps\n",
    "        # Random trade for simulation\n",
    "        ticker = np.random.choice(sample_data.columns.get_level_values('ticker').unique())\n",
    "        action = np.random.choice(['buy', 'sell'])\n",
    "        size = np.random.uniform(0.1, 0.3)\n",
    "        \n",
    "        # Record trade\n",
    "        monitor.record_trade({\n",
    "            'timestamp': timestamp,\n",
    "            'ticker': ticker,\n",
    "            'action': action,\n",
    "            'size': size,\n",
    "            'price': row[(ticker, 'close')]\n",
    "        })\n",
    "    \n",
    "    # Update portfolio state\n",
    "    portfolio_state = {\n",
    "        'timestamp': timestamp,\n",
    "        'portfolio_value': 100000 * (1 + 0.0001 * i),  # Simulated growth\n",
    "        'positions': {\n",
    "            'AAPL': 100,\n",
    "            'MSFT': 50,\n",
    "            'GOOGL': 30\n",
    "        },\n",
    "        'cash': 50000\n",
    "    }\n",
    "    \n",
    "    # Update monitoring\n",
    "    monitor.update_portfolio_state(portfolio_state)\n",
    "    \n",
    "    # Check for alerts\n",
    "    alerts = monitor.check_alerts()\n",
    "    \n",
    "    if alerts:\n",
    "        print(f\"\\nAlerts at {timestamp}:\")\n",
    "        for alert in alerts:\n",
    "            print(f\"  - {alert['type']}: {alert['message']}\")\n",
    "\n",
    "print(\"\\nReal-time monitoring simulation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get monitoring summary\n",
    "summary = monitor.get_summary()\n",
    "\n",
    "print(\"\\nMonitoring Summary:\")\n",
    "print(f\"Current Portfolio Value: ${summary['current_portfolio_value']:,.2f}\")\n",
    "print(f\"Total Return: {summary['total_return']:.2%}\")\n",
    "print(f\"Current Drawdown: {summary['current_drawdown']:.2%}\")\n",
    "print(f\"Sharpe Ratio: {summary['sharpe_ratio']:.2f}\")\n",
    "print(f\"Win Rate: {summary['win_rate']:.2%}\")\n",
    "print(f\"Total Trades: {summary['total_trades']}\")\n",
    "print(f\"Active Alerts: {len(summary['active_alerts'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided comprehensive examples and tutorials for using the Multi-Ticker RL Trading System. We've covered:\n",
    "\n",
    "1. **Basic Multi-Ticker Training**: Training a simple multi-ticker RL model\n",
    "2. **Model Evaluation**: Evaluating model performance on test data\n",
    "3. **Walk-Forward Optimization**: Implementing robust validation with LOT-O CV\n",
    "4. **Hyperparameter Optimization**: Using Optuna for automated hyperparameter tuning\n",
    "5. **Custom Reward Function**: Implementing custom reward functions with diversification and risk management\n",
    "6. **Dynamic Universe Selection**: Adapting to changing market conditions\n",
    "7. **Performance Benchmarking**: Comparing against baseline strategies\n",
    "8. **Real-time Monitoring**: Setting up monitoring and alerting\n",
    "\n",
    "These examples demonstrate the flexibility and power of the Multi-Ticker RL Trading System. You can extend and customize these examples to suit your specific trading requirements and market conditions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}